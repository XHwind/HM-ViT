name: camera_intermediate_fax # only used for demonstration data api
#root_dir: '/home/runshengxu/project/OpenCOOD/opv2v_data_dumping/train'
#validate_dir: '/home/runshengxu/project/OpenCOOD/opv2v_data_dumping/validate'
root_dir: '/home/hao/dataset/opv2v/train'
validate_dir: '/home/hao/dataset/opv2v/test'

yaml_parser: "load_point_pillar_params"
train_params:
  batch_size: &batch_size 1
  epoches: &epoches 151
  eval_freq: 5
  save_freq: 5
  max_cav: &max_cav 5
  visible: true


fusion:
  core_method: 'CamLiIntermediateFusionDataset' # LateFusionDataset, EarlyFusionDataset, IntermediateFusionDataset supported
  args: []


data_augment: []
add_data_extension: []

# preprocess-related
preprocess:
  # options: BasePreprocessor, VoxelPreprocessor, BevPreprocessor
  core_method: CamLiPreprocessor
  cav_lidar_range: &cav_lidar [-102.4, -102.4, -3, 102.4, 102.4, 1]
  args:
    camera_preprocess:
      core_method: 'RgbPreprocessor'
      args:
        bgr2rgb: true
        resize_x: &image_width 512
        resize_y: &image_height 512
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]
      # object evaluation range
      cav_lidar_range: *cav_lidar
    lidar_preprocess:
      core_method: 'SpVoxelPreprocessor'
      args:
        voxel_size: &voxel_size [ 0.4, 0.4, 4 ]
        max_points_per_voxel: 32
        max_voxel_train: 32000
        max_voxel_test: 70000
      cav_lidar_range: *cav_lidar


# anchor box related
postprocess:
  core_method: 'VoxelPostprocessor' # VoxelPostprocessor, BevPostprocessor supported
  anchor_args:
    cav_lidar_range: *cav_lidar
    l: 3.9
    w: 1.6
    h: 1.56
    r: [0, 90]
    feature_stride: 4
    num: &achor_num 2
  target_args:
    pos_threshold: 0.6
    neg_threshold: 0.45
    score_threshold: 0.27
  order: 'hwl' # hwl or lwh
  max_num: 100 # maximum number of objects in a single frame. use this number to make sure different frames has the same dimension in the same batch
  nms_thresh: 0.15

model:
  core_method: 'point_pillar_cross_view_transformer_f_cooper'
  args:
    target: &target 'dynamic' # dynamic, static or both
    max_cav: *max_cav
    anchor_number: *achor_num
    encoder:
      num_layers: 18 # 34
      pretrained: true
      image_width: *image_width
      image_height: *image_height
      id_pick: [1, 2, 3]
    point_pillar_scatter:
      num_features: 64

    compression: 0 # compression rate

    decoder:
      input_dim: 128
      num_layer: 2
      num_ch_dec: &decoder_block [32, 64]

    fax:
      dim: [128, 128, 128] # b, d, h w from resenet -> b 256 h w
      middle: [2, 2, 2] # middle conv
      bev_embedding:
        sigma: 1.0
        bev_height: 256
        bev_width: 256
        h_meters: 100
        w_meters: 100
        offset: 0.0
        upsample_scales: [2, 4, 8]

      cross_view: #cross_view attention
        image_height: *image_height
        image_width: *image_width
        no_image_features: False
        skip: True
        heads: [1, 1, 1]
        dim_head: [8, 8, 8]
        qkv_bias: True

      cross_view_swap:
        rel_pos_emb: False
        q_win_size: [ [ 16, 16 ], [ 16, 16 ], [ 32, 32 ] ]
        feat_win_size: [ [ 8, 8 ], [ 8, 8 ], [ 16, 16 ] ]
        bev_embedding_flag: [ true, false, false ]

      self_attn:
        dim_head: 32
        dropout: 0.1
        window_size: 32

    sttf: &sttf
      resolution: 0.390625 # m/pixel
      downsample_rate: 8
      use_roi_mask: true

    fax_fusion:
      input_dim: 128
      mlp_dim: 256
      agent_size: *max_cav
      window_size: 8
      dim_head: 32
      drop_out: 0.1
      depth: 3
      mask: true


    seg_head_dim: 32
    output_class: 2

loss:
  core_method: point_pillar_loss
  args:
    cls_weight: 1.0
    reg: 2.0

optimizer:
  core_method: AdamW
  lr: 2e-4
  args:
    eps: 1e-10
    weight_decay: 1e-2

lr_scheduler:
    core_method: cosineannealwarm #step, multistep, Exponential and cosineannealwarm support
    epoches: *epoches
    warmup_lr: 2e-5
    warmup_epoches: 10
    lr_min: 5e-6